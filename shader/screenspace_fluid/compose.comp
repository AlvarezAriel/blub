#version 460

#include "../fluid_render_info.glsl"
#include "../per_frame_resources.glsl"
#include "../utilities.glsl"

layout(set = 2, binding = 0) uniform texture2D FluidViewSpaceDepth;
layout(set = 2, binding = 1) uniform texture2D ParticleThickness;
layout(set = 2, binding = 2, HDR_BACKBUFFER_IMAGE_FORMAT) uniform restrict image2D BackbufferImage;

layout(local_size_x = 32, local_size_y = 32, local_size_z = 1) in;

// TODO: Will certainly come in handy.
const float RefractionIndex_Water = 1.33;
const float RefractionIndex_Air = 1.00029;
const float RefractionAirToWater = RefractionIndex_Air / RefractionIndex_Water;

vec3 computeRefractionColor(float particleThickness) {
    // TODO: Compute refaction
    vec3 refractionRayResult = imageLoad(BackbufferImage, ivec2(gl_GlobalInvocationID.xy)).xyz;

    // TODO: can we adjust thickness value to become a "seen water depth value"? Refraction vector goes through more water than this.
    float waterRefractionDepth = particleThickness * 100;

    // Water color
    // This otherwise quite convincing reference assumes linear extinction, I'll go with exponential-
    // http://www.gamedev.net/page/reference/index.html/_/technical/graphics-programming-and-theory/rendering-water-as-a-post-process-effect-r2642
    // This leaves the questions: What are convining Extinction coefficients?
    // For that I solved the equations exp(-4.5 * R) = exp(-75 * G) = exp(-300 * B) = 0.001 (depths are from link above)
    // .. which is.. convincing pseudo physical! :)
    // In reality water color depends on a lot of factors: https://en.wikipedia.org/wiki/Color_of_water
    const vec3 ColorExtinctionCoefficient = vec3(1.53506, 0.0921034, 0.0230259);
    const vec3 SurfaceColor = vec3(0.003, 0.179, 0.270);
    const vec3 BigDepthColor = vec3(0.002, 0.001, 0.072);
    const float Opaqueness = 0.1;

    vec3 colorExtinction = saturate(exp(-waterRefractionDepth * ColorExtinctionCoefficient));
    vec3 normalLightingColor = vec3(1.0); // GlobalDirLightColor * nDotL + GlobalAmbient;
    vec3 waterColor = mix(refractionRayResult, SurfaceColor * normalLightingColor, saturate(waterRefractionDepth * Opaqueness));

    return mix(vec3(0.0), waterColor, colorExtinction);
}

// Computes world space position from standard depth buffer depth.
// (using "classic depth buffer", as defined in with our global camera matrices)
vec3 reconstructWorldPositionFromViewSpaceDepth(vec2 screenUv, float depth) {
    float x = screenUv.x * 2.0f - 1.0f;
    float y = (1.0 - screenUv.y) * 2.0f - 1.0f;
    vec3 viewSpace = vec3(Camera.NdcCameraSpaceProjected * vec2(x, y) * depth, depth);
    return viewSpace.x * Camera.Right + viewSpace.y * Camera.Up + viewSpace.z * Camera.Direction + Camera.Position;
}

vec3 reconstructNormalFromDepthbuffer(ivec2 screenCoord, vec2 screenPixelSize) {
    // Use a better method as described here?
    // https://wickedengine.net/2019/09/22/improved-normal-reconstruction-from-depth/
    // (Improved normal reconstruction from depth, Turanszkij, September 2019)
    // Btw. here is an even more thorough and expensive one: https://atyuwen.github.io/posts/normal-reconstruction/#fn:2

    ivec2 coord0 = screenCoord;
    ivec2 coord1 = screenCoord + ivec2(0, 1);
    ivec2 coord2 = screenCoord + ivec2(1, 0);

    // TODO: Shared memory?
    float depth0 = texelFetch(FluidViewSpaceDepth, coord0, 0).r;
    float depth1 = texelFetch(FluidViewSpaceDepth, coord1, 0).r;
    float depth2 = texelFetch(FluidViewSpaceDepth, coord2, 0).r;

    vec3 p0 = reconstructWorldPositionFromViewSpaceDepth(coord0 * screenPixelSize, depth0);
    vec3 p1 = reconstructWorldPositionFromViewSpaceDepth(coord1 * screenPixelSize, depth1);
    vec3 p2 = reconstructWorldPositionFromViewSpaceDepth(coord2 * screenPixelSize, depth2);

    return normalize(cross(p1 - p0, p2 - p0));
}

void main() {
    ivec2 screenCoord = ivec2(gl_GlobalInvocationID.xy);
    float particleThickness = texelFetch(ParticleThickness, screenCoord, 0).r;
    if (particleThickness == 0.0)
        return;

    vec2 screenPixelSize = vec2(1.0) / textureSize(FluidViewSpaceDepth, 0).xy;

    vec3 waterSurfaceNormal = reconstructNormalFromDepthbuffer(screenCoord, screenPixelSize);

    vec4 previousColor = imageLoad(BackbufferImage, screenCoord);

    vec3 refractionColor = computeRefractionColor(particleThickness);
    vec4 outputColor = vec4(dot(waterSurfaceNormal, normalize(vec3(-1.0, 0.5, 0.5))).xxx, 0.0);
    outputColor = vec4(waterSurfaceNormal, 0.0);
    // outputColor = texelFetch(FluidViewSpaceDepth, screenCoord, 0).rrrr;
    // outputColor = reconstructWorldPositionFromViewSpaceDepth(screenPixelSize * screenCoord, texelFetch(FluidViewSpaceDepth, screenCoord,
    // 0).r).xyzz;
    imageStore(BackbufferImage, screenCoord, outputColor);
}